#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
validate_index.py ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
  1. Top-K accuracy (–º–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç —Å–≤–æ–∏ —Ñ–æ—Ç–æ?)
  2. Mean Reciprocal Rank (MRR)
  3. Mean Average Precision (MAP)
  4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ match
  5. Preprocessing consistency (query vs index)
  6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
  python scripts/validate_index.py --test-size 100
  
  # –ü–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
  python scripts/validate_index.py --test-size 500 --visualize --save-failures
  
  # –¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ preprocessing
  python scripts/validate_index.py --check-preprocessing
"""

from __future__ import annotations
import os
import sys
import json
import argparse
import random
from pathlib import Path
from collections import defaultdict
from typing import List, Tuple, Dict

import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns

import torch
import hnswlib

# ========================= –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã =========================
SEED = 42
DEFAULT_TILE_SIZE = 336
DEFAULT_TILE_STRIDE = 224
DEFAULT_EF = 256

# ========================= –£—Ç–∏–ª–∏—Ç—ã =========================

def pick_device():
    """–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
    if torch.backends.mps.is_available():
        return torch.device("mps")
    if torch.cuda.is_available():
        return torch.device("cuda")
    return torch.device("cpu")


def load_model_from_index(index_dir: Path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ CLIP –º–æ–¥–µ–ª–∏ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞"""
    import open_clip
    
    index_dir = Path(index_dir)
    model_name = "ViT-L-14"
    pretrained = "openai"
    
    meta_json = index_dir / "model.json"
    if meta_json.exists():
        try:
            meta = json.loads(meta_json.read_text())
            model_name = meta.get("model", model_name)
            pretrained = meta.get("pretrained", pretrained)
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è model.json: {e}")
    
    try:
        model, _, preprocess = open_clip.create_model_and_transforms(
            model_name, pretrained=pretrained
        )
    except Exception as e:
        print(f"[!] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        sys.exit(1)
    
    model.eval()
    return model, preprocess, model_name


def tile_image_pil(pil_img: Image.Image, size=336, stride=224):
    """–¢–∞–π–ª–∏–Ω–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º"""
    W, H = pil_img.size
    tiles = []
    
    for y in range(0, max(1, H - size + 1), stride):
        for x in range(0, max(1, W - size + 1), stride):
            tile = pil_img.crop((x, y, x + size, y + size))
            tiles.append(tile)
    
    if not tiles:
        tiles = [pil_img.resize((size, size), Image.BICUBIC)]
    
    return tiles


def compute_query_embedding(
    img_path: str,
    model,
    preprocess,
    device,
    tile_size=336,
    tile_stride=224,
    aggregation="max"
):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞ (–∫–∞–∫ –≤ 05_query.py)"""
    img = Image.open(img_path).convert("RGB")
    tiles = tile_image_pil(img, size=tile_size, stride=tile_stride)
    
    embeds = []
    with torch.inference_mode():
        for t in tiles:
            ten = preprocess(t).unsqueeze(0).to(device)
            e = model.encode_image(ten)
            e = torch.nn.functional.normalize(e, dim=-1)
            embeds.append(e)
    
    E = torch.stack(embeds, dim=0).squeeze(1)  # [T, D]
    
    if aggregation == "max":
        q_emb = torch.amax(E, dim=0)
    elif aggregation == "mean":
        q_emb = torch.mean(E, dim=0)
    elif aggregation == "first":
        q_emb = E[0]
    else:
        raise ValueError(f"Unknown aggregation: {aggregation}")
    
    q_emb = q_emb.detach().cpu().numpy()
    q_emb = q_emb / (np.linalg.norm(q_emb) + 1e-9)
    
    return q_emb


# ========================= –ú–µ—Ç—Ä–∏–∫–∏ =========================

def compute_metrics(results: List[Dict], verbose=True):
    """
    –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    
    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏:
            - query_idx: –∏–Ω–¥–µ–∫—Å –∑–∞–ø—Ä–æ—Å–∞
            - ground_truth: —Å–ø–∏—Å–æ–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
            - retrieved: —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
    
    Returns:
        Dict —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    topk_acc = {1: 0, 5: 0, 10: 0, 50: 0, 100: 0}
    reciprocal_ranks = []
    avg_precisions = []
    distances = []  # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ match
    
    for res in results:
        gt_set = set(res["ground_truth"])
        retrieved = res["retrieved"]
        
        # Top-K accuracy
        for k in topk_acc.keys():
            if any(idx in gt_set for idx in retrieved[:k]):
                topk_acc[k] += 1
        
        # Reciprocal Rank
        rank = None
        for i, idx in enumerate(retrieved):
            if idx in gt_set:
                rank = i + 1
                break
        
        if rank is not None:
            reciprocal_ranks.append(1.0 / rank)
            distances.append(rank)
        else:
            reciprocal_ranks.append(0.0)
            distances.append(len(retrieved) + 1)
        
        # Average Precision
        hits = 0
        precisions = []
        for i, idx in enumerate(retrieved):
            if idx in gt_set:
                hits += 1
                precisions.append(hits / (i + 1))
        
        if precisions:
            avg_precisions.append(np.mean(precisions))
        else:
            avg_precisions.append(0.0)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    n = len(results)
    for k in topk_acc.keys():
        topk_acc[k] = (topk_acc[k] / n) * 100.0
    
    mrr = np.mean(reciprocal_ranks) if reciprocal_ranks else 0.0
    map_score = np.mean(avg_precisions) if avg_precisions else 0.0
    
    metrics = {
        "top1_acc": topk_acc[1],
        "top5_acc": topk_acc[5],
        "top10_acc": topk_acc[10],
        "top50_acc": topk_acc[50],
        "top100_acc": topk_acc[100],
        "mrr": mrr,
        "map": map_score,
        "mean_distance": np.mean(distances),
        "median_distance": np.median(distances),
    }
    
    if verbose:
        print("\n" + "=" * 60)
        print("üìä –ú–ï–¢–†–ò–ö–ò –í–ê–õ–ò–î–ê–¶–ò–ò")
        print("=" * 60)
        print(f"Top-1 Accuracy:   {metrics['top1_acc']:>6.2f}%")
        print(f"Top-5 Accuracy:   {metrics['top5_acc']:>6.2f}%")
        print(f"Top-10 Accuracy:  {metrics['top10_acc']:>6.2f}%")
        print(f"Top-50 Accuracy:  {metrics['top50_acc']:>6.2f}%")
        print(f"Top-100 Accuracy: {metrics['top100_acc']:>6.2f}%")
        print(f"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}")
        print(f"Mean Average Precision (MAP): {metrics['map']:.4f}")
        print(f"Mean Distance to GT: {metrics['mean_distance']:.1f}")
        print(f"Median Distance to GT: {metrics['median_distance']:.1f}")
        print("=" * 60)
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        if metrics['top1_acc'] >= 90:
            print("‚úÖ –û–¢–õ–ò–ß–ù–û! –ú–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç —Å–≤–æ–∏ —Ñ–æ—Ç–æ.")
        elif metrics['top1_acc'] >= 70:
            print("‚ö†Ô∏è  –ü–†–ò–ï–ú–õ–ï–ú–û, –Ω–æ –µ—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è.")
        elif metrics['top1_acc'] >= 50:
            print("‚ö†Ô∏è  –ü–†–û–ë–õ–ï–ú–ê! Top-1 accuracy —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è.")
        else:
            print("üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê! –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç —Å–≤–æ–∏ —Ñ–æ—Ç–æ!")
            print("   –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            print("   1. Preprocessing mismatch (query ‚â† index)")
            print("   2. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è")
            print("   3. Tile aggregation —Å–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è")
            print("   4. –ü—Ä–æ–±–ª–µ–º—ã —Å –º–æ–¥–µ–ª—å—é/–≤–µ—Å–∞–º–∏")
    
    return metrics


# ========================= –í–∞–ª–∏–¥–∞—Ü–∏—è =========================

def validate_index(
    index_dir: Path,
    crops_meta: Path,
    test_size: int = 100,
    ef: int = 256,
    topk: int = 100,
    tile_size: int = 336,
    tile_stride: int = 224,
    aggregation: str = "max",
    save_failures: bool = False,
    visualize: bool = False,
):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞"""
    
    print(f"[i] –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
    meta_parquet = index_dir / "crops.parquet"
    if meta_parquet.exists():
        meta = pd.read_parquet(meta_parquet)
    else:
        meta = pd.read_csv(crops_meta)
    
    print(f"[‚úì] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(meta)} –∫—Ä–æ–ø–æ–≤")
    
    # –í—ã–±–æ—Ä–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    random.seed(SEED)
    valid_indices = [i for i in range(len(meta)) if os.path.exists(meta.iloc[i]["path"])]
    
    if len(valid_indices) < test_size:
        print(f"[!] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({len(valid_indices)}), —É–º–µ–Ω—å—à–∞—é test_size")
        test_size = len(valid_indices)
    
    test_indices = random.sample(valid_indices, test_size)
    print(f"[i] –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {test_size} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print(f"\n[i] –ó–∞–≥—Ä—É–∑–∫–∞ CLIP –º–æ–¥–µ–ª–∏...")
    device = pick_device()
    model, preprocess, model_name = load_model_from_index(index_dir)
    model.to(device)
    print(f"[‚úì] –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_name} –Ω–∞ {device}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞
    print(f"\n[i] –ó–∞–≥—Ä—É–∑–∫–∞ HNSW –∏–Ω–¥–µ–∫—Å–∞...")
    index_path = index_dir / "hnsw.bin"
    if not index_path.exists():
        print(f"[!] –ù–µ –Ω–∞–π–¥–µ–Ω –∏–Ω–¥–µ–∫—Å: {index_path}")
        sys.exit(1)
    
    embs_path = index_dir / "embs.npy"
    embs = np.load(embs_path)
    dim = embs.shape[1]
    
    index = hnswlib.Index(space="cosine", dim=dim)
    index.load_index(str(index_path))
    index.set_ef(ef)
    print(f"[‚úì] HNSW –≥–æ—Ç–æ–≤ (ef={ef})")
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    print(f"\n[i] –ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
    results = []
    
    for test_idx in tqdm(test_indices, desc="–í–∞–ª–∏–¥–∞—Ü–∏—è", unit="img"):
        row = meta.iloc[test_idx]
        img_path = row["path"]
        pano_id = row["pano_id"]
        
        try:
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
            q_emb = compute_query_embedding(
                img_path, model, preprocess, device,
                tile_size=tile_size, tile_stride=tile_stride,
                aggregation=aggregation
            )
            
            # –ü–æ–∏—Å–∫
            labels, dists = index.knn_query(q_emb, k=topk)
            retrieved = labels[0].tolist()
            
            # Ground truth ‚Äî –≤—Å–µ –∫—Ä–æ–ø—ã —ç—Ç–æ–π –ø–∞–Ω–æ—Ä–∞–º—ã
            gt_indices = meta[meta["pano_id"] == pano_id].index.tolist()
            
            results.append({
                "query_idx": test_idx,
                "pano_id": pano_id,
                "ground_truth": gt_indices,
                "retrieved": retrieved,
                "distances": dists[0].tolist(),
            })
            
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –¥–ª—è {img_path}: {e}")
            continue
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    metrics = compute_metrics(results, verbose=True)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_path = index_dir / "validation_results.json"
    with open(results_path, "w") as f:
        json.dump({
            "metrics": metrics,
            "test_size": test_size,
            "config": {
                "ef": ef,
                "topk": topk,
                "tile_size": tile_size,
                "tile_stride": tile_stride,
                "aggregation": aggregation,
            },
        }, f, indent=2)
    
    print(f"\n[‚úì] –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    if visualize:
        visualize_results(results, meta, index_dir)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ failures
    if save_failures:
        save_failure_cases(results, meta, index_dir)
    
    return metrics, results


def visualize_results(results: List[Dict], meta: pd.DataFrame, index_dir: Path):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    print(f"\n[i] –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
    
    vis_dir = index_dir / "validation_viz"
    vis_dir.mkdir(exist_ok=True)
    
    # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–Ω–≥–æ–≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ match
    ranks = []
    for res in results:
        gt_set = set(res["ground_truth"])
        for i, idx in enumerate(res["retrieved"]):
            if idx in gt_set:
                ranks.append(i + 1)
                break
        else:
            ranks.append(len(res["retrieved"]) + 1)
    
    plt.figure(figsize=(10, 6))
    plt.hist(ranks, bins=50, edgecolor='black')
    plt.xlabel("Rank of Ground Truth")
    plt.ylabel("Frequency")
    plt.title("Distribution of Ground Truth Ranks")
    plt.yscale("log")
    plt.grid(True, alpha=0.3)
    plt.savefig(vis_dir / "ranks_distribution.png", dpi=150, bbox_inches="tight")
    plt.close()
    
    # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ cosine distances
    distances = []
    for res in results:
        distances.extend(res["distances"][:10])  # Top-10
    
    plt.figure(figsize=(10, 6))
    plt.hist(distances, bins=50, edgecolor='black')
    plt.xlabel("Cosine Distance")
    plt.ylabel("Frequency")
    plt.title("Distribution of Cosine Distances (Top-10)")
    plt.grid(True, alpha=0.3)
    plt.savefig(vis_dir / "distances_distribution.png", dpi=150, bbox_inches="tight")
    plt.close()
    
    print(f"[‚úì] –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {vis_dir}")


def save_failure_cases(results: List[Dict], meta: pd.DataFrame, index_dir: Path):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ª—É—á–∞–µ–≤ –≥–¥–µ –º–æ–¥–µ–ª—å –æ—à–∏–±–ª–∞—Å—å"""
    print(f"\n[i] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ failure cases...")
    
    failures_dir = index_dir / "validation_failures"
    failures_dir.mkdir(exist_ok=True)
    
    failures = []
    for res in results:
        gt_set = set(res["ground_truth"])
        top1_idx = res["retrieved"][0]
        
        if top1_idx not in gt_set:
            failures.append({
                "query_idx": res["query_idx"],
                "query_pano": res["pano_id"],
                "retrieved_idx": top1_idx,
                "retrieved_pano": meta.iloc[top1_idx]["pano_id"],
                "distance": res["distances"][0],
            })
    
    if failures:
        failures_path = failures_dir / "failures.json"
        with open(failures_path, "w") as f:
            json.dump(failures, f, indent=2)
        
        print(f"[‚úì] –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(failures)} failures: {failures_path}")
    else:
        print("[‚úì] –ù–µ—Ç failures!")


# ========================= –ü—Ä–æ–≤–µ—Ä–∫–∞ preprocessing =========================

def check_preprocessing_consistency(index_dir: Path, crops_meta: Path):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç consistency –º–µ–∂–¥—É preprocessing –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏ query
    """
    print("\n" + "=" * 60)
    print("üîç –ü–†–û–í–ï–†–ö–ê PREPROCESSING CONSISTENCY")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞
    meta_parquet = index_dir / "crops.parquet"
    if meta_parquet.exists():
        meta = pd.read_parquet(meta_parquet)
    else:
        meta = pd.read_csv(crops_meta)
    
    device = pick_device()
    model, preprocess, model_name = load_model_from_index(index_dir)
    model.to(device)
    
    embs_path = index_dir / "embs.npy"
    index_embs = np.load(embs_path)
    
    # –í—ã–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª—É—á–∞–π–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    random.seed(SEED)
    test_indices = random.sample(range(len(meta)), min(10, len(meta)))
    
    diffs = []
    for idx in test_indices:
        row = meta.iloc[idx]
        img_path = row["path"]
        
        if not os.path.exists(img_path):
            continue
        
        try:
            # –í—ã—á–∏—Å–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ "–∫–∞–∫ –ø—Ä–∏ query"
            img = Image.open(img_path).convert("RGB")
            with torch.inference_mode():
                ten = preprocess(img).unsqueeze(0).to(device)
                e = model.encode_image(ten)
                e = torch.nn.functional.normalize(e, dim=-1)
                query_emb = e.detach().cpu().numpy()[0]
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            query_emb = query_emb / (np.linalg.norm(query_emb) + 1e-9)
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º
            index_emb = index_embs[idx]
            
            # Cosine similarity
            cos_sim = np.dot(query_emb, index_emb)
            diff = 1.0 - cos_sim
            
            diffs.append(diff)
            
            print(f"[{idx:>5}] Cosine diff: {diff:.6f} (similarity: {cos_sim:.6f})")
            
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –¥–ª—è {img_path}: {e}")
            continue
    
    if diffs:
        mean_diff = np.mean(diffs)
        max_diff = np.max(diffs)
        
        print("\n" + "-" * 60)
        print(f"Mean preprocessing diff: {mean_diff:.6f}")
        print(f"Max preprocessing diff:  {max_diff:.6f}")
        print("-" * 60)
        
        if mean_diff < 0.001:
            print("‚úÖ –ò–î–ï–ê–õ–¨–ù–û! Preprocessing –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞–µ—Ç.")
        elif mean_diff < 0.01:
            print("‚úÖ –•–û–†–û–®–û! Preprocessing –ø–æ—á—Ç–∏ –∏–¥–µ–Ω—Ç–∏—á–µ–Ω.")
        elif mean_diff < 0.05:
            print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –ï—Å—Ç—å –Ω–µ–±–æ–ª—å—à–∏–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ preprocessing.")
        else:
            print("üî• –ü–†–û–ë–õ–ï–ú–ê! Preprocessing —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è!")
            print("   –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            print("   1. –†–∞–∑–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã resize/crop")
            print("   2. –†–∞–∑–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è")
            print("   3. –†–∞–∑–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ (PIL, torchvision)")
    
    print("=" * 60)


# ========================= Main =========================

def main():
    parser = argparse.ArgumentParser(
        description="–í–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π"
    )
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("--index-dir", default="index", help="–ü–∞–ø–∫–∞ —Å –∏–Ω–¥–µ–∫—Å–æ–º")
    parser.add_argument("--crops-meta", default="meta/crops.csv", help="–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫—Ä–æ–ø–æ–≤")
    parser.add_argument("--test-size", type=int, default=100, help="–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏")
    
    # HNSW –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("--ef", type=int, default=DEFAULT_EF, help="HNSW ef parameter")
    parser.add_argument("--topk", type=int, default=100, help="–°–∫–æ–ª—å–∫–æ —Å–æ—Å–µ–¥–µ–π –∏—Å–∫–∞—Ç—å")
    
    # Query –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("--tile-size", type=int, default=DEFAULT_TILE_SIZE)
    parser.add_argument("--tile-stride", type=int, default=DEFAULT_TILE_STRIDE)
    parser.add_argument("--aggregation", choices=["max", "mean", "first"], default="max",
                       help="–ú–µ—Ç–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Ç–∞–π–ª–æ–≤")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
    parser.add_argument("--visualize", action="store_true", help="–°–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
    parser.add_argument("--save-failures", action="store_true", help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å failure cases")
    parser.add_argument("--check-preprocessing", action="store_true",
                       help="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å preprocessing consistency")
    
    args = parser.parse_args()
    
    index_dir = Path(args.index_dir)
    crops_meta = Path(args.crops_meta)
    
    if not index_dir.exists():
        print(f"[!] –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞ –∏–Ω–¥–µ–∫—Å–∞: {index_dir}")
        sys.exit(1)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ preprocessing
    if args.check_preprocessing:
        check_preprocessing_consistency(index_dir, crops_meta)
        return
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    validate_index(
        index_dir=index_dir,
        crops_meta=crops_meta,
        test_size=args.test_size,
        ef=args.ef,
        topk=args.topk,
        tile_size=args.tile_size,
        tile_stride=args.tile_stride,
        aggregation=args.aggregation,
        save_failures=args.save_failures,
        visualize=args.visualize,
    )


if __name__ == "__main__":
    main()